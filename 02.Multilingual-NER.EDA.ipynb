{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce9f8233",
   "metadata": {},
   "source": [
    "# Распознавание именованных сущностей\n",
    "*Исследовательский анализ данных*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648ec232",
   "metadata": {},
   "source": [
    "## Датасет\n",
    "\n",
    "Будем использовать подмножество из *Cross-lingual Transfer Evaluation of Multilingual Encoders (XTREME)*, называемый *WikiANN* или *PAN-X*.\n",
    "\n",
    "Датасет содержит статьи из Википедии на многих языках, включая 4 наиболее распространенных языков в Швейцарии:\n",
    "- *Немецкий (62.9%)*,\n",
    "- *Французский (22.9%)*,\n",
    "- *Итальянский (8.4%)*,\n",
    "- *Английский (5.9%)*.\n",
    "\n",
    "Статьи аннотированы тегами\n",
    "- *LOC (location)*,\n",
    "- *PER (person)*,\n",
    "- *ORG (organization)*\n",
    "\n",
    "в формате *inside-outside-beginning (IOB2)*. В этом формате\n",
    "- начало токена сущности помечается с префиксом `B-`,\n",
    "- токены, не являющиеся начальными, но входящие в состав именной сущности, помечаются префиксом `I-`.\n",
    "- Токены, не имеющие отношение к сущности, помечаются `O`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42207e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misha/.pyenv/versions/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTREME имеет 183 конфигураций\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
    "print(f\"XTREME имеет {len(xtreme_subsets)} конфигураций\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c98c22",
   "metadata": {},
   "source": [
    "Нам нужны только *PAN-X* подмножества для наших 4-ех языков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2483d6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAN-X.af', 'PAN-X.ar', 'PAN-X.bg', 'PAN-X.bn', 'PAN-X.de']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_subsets = [s for s in xtreme_subsets if s.startswith(\"PAN\")]\n",
    "panx_subsets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba13e0a1",
   "metadata": {},
   "source": [
    "Чтобы создать реалистичный Швейцарский корпус, нам сделать так, чтобы количество образцов в языке соответствовало распределению языков в стране. В датасетах разных языков одинаковое количество образцов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543d85f0",
   "metadata": {},
   "source": [
    "### Загрузка датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afa24812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "langs = [\"de\", \"fr\", \"it\", \"en\"]\n",
    "fracs = [0.629, 0.229, 0.084, 0.059]\n",
    "\n",
    "panx_ch = defaultdict(DatasetDict)\n",
    "\n",
    "for lang, frac in zip(langs, fracs):\n",
    "    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
    "    for split in ds:\n",
    "        panx_ch[lang][split] = (\n",
    "            ds[split]\n",
    "            .shuffle(seed=42)\n",
    "            .select(range(int(frac * ds[split].num_rows)))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96183034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Количество тренировочных образцов</th>\n",
       "      <td>12580</td>\n",
       "      <td>4580</td>\n",
       "      <td>1680</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      de    fr    it    en\n",
       "Количество тренировочных образцов  12580  4580  1680  1180"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(\n",
    "    {lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs},\n",
    "    index=[\"Количество тренировочных образцов\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfa7517",
   "metadata": {},
   "source": [
    "### Обзор образцов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0054d8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['Olympique', 'Nîmes', ',', 'Auxerres', 'seinerzeitiger', 'drittklassiger', 'Endspielgegner', ',', 'hatte', 'sich', 'erst', 'gar', 'nicht', 'für', 'die', 'Hauptrunde', 'qualifizieren', 'können', '.']\n",
      "ner_tags: [3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "langs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n"
     ]
    }
   ],
   "source": [
    "for k, v in panx_ch[\"de\"][\"train\"][0].items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07cb9ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'])\n"
     ]
    }
   ],
   "source": [
    "tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a98dfec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tag_names(batch):\n",
    "    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n",
    "\n",
    "\n",
    "panx_de = panx_ch[\"de\"].map(create_tag_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "869855e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>Olympique</td>\n",
       "      <td>Nîmes</td>\n",
       "      <td>,</td>\n",
       "      <td>Auxerres</td>\n",
       "      <td>seinerzeitiger</td>\n",
       "      <td>drittklassiger</td>\n",
       "      <td>Endspielgegner</td>\n",
       "      <td>,</td>\n",
       "      <td>hatte</td>\n",
       "      <td>sich</td>\n",
       "      <td>erst</td>\n",
       "      <td>gar</td>\n",
       "      <td>nicht</td>\n",
       "      <td>für</td>\n",
       "      <td>die</td>\n",
       "      <td>Hauptrunde</td>\n",
       "      <td>qualifizieren</td>\n",
       "      <td>können</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0      1  2         3               4               5   \\\n",
       "Tokens  Olympique  Nîmes  ,  Auxerres  seinerzeitiger  drittklassiger   \n",
       "Tags        B-ORG  I-ORG  O         O               O               O   \n",
       "\n",
       "                    6  7      8     9     10   11     12   13   14  \\\n",
       "Tokens  Endspielgegner  ,  hatte  sich  erst  gar  nicht  für  die   \n",
       "Tags                 O  O      O     O     O    O      O    O    O   \n",
       "\n",
       "                15             16      17 18  \n",
       "Tokens  Hauptrunde  qualifizieren  können  .  \n",
       "Tags             O              O       O  O  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_example = panx_de[\"train\"][0]\n",
    "pd.DataFrame(\n",
    "    [de_example[\"tokens\"], de_example[\"ner_tags_str\"]], [\"Tokens\", \"Tags\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f958907e",
   "metadata": {},
   "source": [
    "### Распределение тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0579d374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORG</th>\n",
       "      <th>PER</th>\n",
       "      <th>LOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>5397</td>\n",
       "      <td>5881</td>\n",
       "      <td>6169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>2639</td>\n",
       "      <td>2870</td>\n",
       "      <td>3172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>2657</td>\n",
       "      <td>2971</td>\n",
       "      <td>3100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ORG   PER   LOC\n",
       "train       5397  5881  6169\n",
       "validation  2639  2870  3172\n",
       "test        2657  2971  3100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "split2freqs = defaultdict(Counter)\n",
    "for split, dataset in panx_de.items():\n",
    "    for row in dataset[\"ner_tags_str\"]:\n",
    "        for tag in row:\n",
    "            if tag.startswith(\"B\"):\n",
    "                tag_type = tag.split(\"-\")[1]\n",
    "                split2freqs[split][tag_type] += 1\n",
    "\n",
    "pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f4dc72",
   "metadata": {},
   "source": [
    "### Модель\n",
    "\n",
    "Напишем сами голову к `XML-RoBERTa` для классификации токенов, хоть и есть готовый класс для этого (`XLMRobertaForTokenClassification`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc4ef629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "\n",
    "\n",
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        labels=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            **kwargs,\n",
    "        )\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a48027",
   "metadata": {},
   "source": [
    "## Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a69f31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48ff27de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "\n",
    "xlmr_config = AutoConfig.from_pretrained(\n",
    "    xlmr_model_name,\n",
    "    num_labels=tags.num_classes,\n",
    "    id2label=index2tag,\n",
    "    label2id=tag2index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ac623a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)\n",
    "\n",
    "xlmr_model = XLMRobertaForTokenClassification.from_pretrained(\n",
    "    xlmr_model_name, config=xlmr_config\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "752f3c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input IDs</th>\n",
       "      <td>0</td>\n",
       "      <td>21763</td>\n",
       "      <td>37456</td>\n",
       "      <td>15555</td>\n",
       "      <td>5161</td>\n",
       "      <td>7</td>\n",
       "      <td>2356</td>\n",
       "      <td>5753</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1      2      3      4  5     6      7   8     9\n",
       "Tokens     <s>  ▁Jack  ▁Spar    row  ▁love  s  ▁New  ▁York   !  </s>\n",
       "Input IDs    0  21763  37456  15555   5161  7  2356   5753  38     2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Jack Sparrow loves New York!\"\n",
    "tokenized_text = xlmr_tokenizer(text, return_tensors=\"pt\")\n",
    "pd.DataFrame(\n",
    "    [tokenized_text.tokens(), tokenized_text.input_ids[0].numpy()],\n",
    "    index=[\"Tokens\", \"Input IDs\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d15f9964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число токенов в последовательности 10\n",
      "Размерность выхода torch.Size([1, 10, 7])\n"
     ]
    }
   ],
   "source": [
    "outputs = xlmr_model(tokenized_text.input_ids.to(device)).logits\n",
    "predictions = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "print(f\"Число токенов в последовательности {len(tokenized_text.tokens())}\")\n",
    "print(f\"Размерность выхода {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65889f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2      3      4      5      6      7      8      9\n",
       "Tokens    <s>  ▁Jack  ▁Spar    row  ▁love      s   ▁New  ▁York      !   </s>\n",
       "Tags    I-PER  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-PER  I-PER  I-LOC  I-PER"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "pd.DataFrame([tokenized_text.tokens(), preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6b7de5",
   "metadata": {},
   "source": [
    "## Токенизация\n",
    "\n",
    "Датасет состоит из разбитых на слова токенов. Наш токенизатор разбивает эти слова на подслова. Мы можем классифицировать только начало слово, а остальную часть игнорировать. Это снизит вклад в функцию потерь длинных слов, которые состоят из нескольких токенов.\n",
    "\n",
    "В этом поможет метод `tokenized_text.word_ids()`, которая возвращает индексы слов, из которых получены subtoken-ы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24e2fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "words, labels = de_example[\"tokens\"], de_example[\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ec85d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Olymp</td>\n",
       "      <td>ique</td>\n",
       "      <td>▁N</td>\n",
       "      <td>îm</td>\n",
       "      <td>es</td>\n",
       "      <td>▁</td>\n",
       "      <td>,</td>\n",
       "      <td>▁Au</td>\n",
       "      <td>xer</td>\n",
       "      <td>...</td>\n",
       "      <td>▁die</td>\n",
       "      <td>▁Haupt</td>\n",
       "      <td>runde</td>\n",
       "      <td>▁quali</td>\n",
       "      <td>fi</td>\n",
       "      <td>zieren</td>\n",
       "      <td>▁können</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1     2   3   4   5  6  7    8    9   ...    28      29  \\\n",
       "Tokens     <s>  ▁Olymp  ique  ▁N  îm  es  ▁  ,  ▁Au  xer  ...  ▁die  ▁Haupt   \n",
       "Word IDs  None       0     0   1   1   1  2  2    3    3  ...    14      15   \n",
       "\n",
       "             30      31  32      33       34  35  36    37  \n",
       "Tokens    runde  ▁quali  fi  zieren  ▁können   ▁   .  </s>  \n",
       "Word IDs     15      16  16      16       17  18  18  None  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_input = xlmr_tokenizer(words, is_split_into_words=True)\n",
    "tokens = xlmr_tokenizer.convert_ids_to_tokens(tokenizer_input[\"input_ids\"])\n",
    "word_ids = tokenizer_input.word_ids()\n",
    "\n",
    "pd.DataFrame([tokens, word_ids], index=[\"Tokens\", \"Word IDs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03815427",
   "metadata": {},
   "source": [
    "`torch.nn.CrossEntropyLoss` по-умолчанию имеет `ignore_index=-100`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02165bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Olymp</td>\n",
       "      <td>ique</td>\n",
       "      <td>▁N</td>\n",
       "      <td>îm</td>\n",
       "      <td>es</td>\n",
       "      <td>▁</td>\n",
       "      <td>,</td>\n",
       "      <td>▁Au</td>\n",
       "      <td>xer</td>\n",
       "      <td>...</td>\n",
       "      <td>▁die</td>\n",
       "      <td>▁Haupt</td>\n",
       "      <td>runde</td>\n",
       "      <td>▁quali</td>\n",
       "      <td>fi</td>\n",
       "      <td>zieren</td>\n",
       "      <td>▁können</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label IDs</th>\n",
       "      <td>-100</td>\n",
       "      <td>3</td>\n",
       "      <td>-100</td>\n",
       "      <td>4</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <td>IGN</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0       1     2      3     4     5  6     7    8     9   ...  \\\n",
       "Tokens      <s>  ▁Olymp  ique     ▁N    îm    es  ▁     ,  ▁Au   xer  ...   \n",
       "Word IDs   None       0     0      1     1     1  2     2    3     3  ...   \n",
       "Label IDs  -100       3  -100      4  -100  -100  0  -100    0  -100  ...   \n",
       "Labels      IGN   B-ORG   IGN  I-ORG   IGN   IGN  O   IGN    O   IGN  ...   \n",
       "\n",
       "             28      29     30      31    32      33       34  35    36    37  \n",
       "Tokens     ▁die  ▁Haupt  runde  ▁quali    fi  zieren  ▁können   ▁     .  </s>  \n",
       "Word IDs     14      15     15      16    16      16       17  18    18  None  \n",
       "Label IDs     0       0   -100       0  -100    -100        0   0  -100  -100  \n",
       "Labels        O       O    IGN       O   IGN     IGN        O   O   IGN   IGN  \n",
       "\n",
       "[4 rows x 38 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_word_idx = None\n",
    "label_ids = []\n",
    "\n",
    "for word_idx in word_ids:\n",
    "    if word_idx is None or word_idx == prev_word_idx:\n",
    "        label_ids.append(-100)\n",
    "    elif word_idx != prev_word_idx:\n",
    "        label_ids.append(labels[word_idx])\n",
    "    prev_word_idx = word_idx\n",
    "\n",
    "labels = [index2tag[l] if l != -100 else \"IGN\" for l in label_ids]\n",
    "index = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\n",
    "\n",
    "pd.DataFrame([tokens, word_ids, label_ids, labels], index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05ee39e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = xlmr_tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for idx, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        prev_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == prev_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            prev_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da00aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_panx_dataset(corpus):\n",
    "    return corpus.map(\n",
    "        tokenize_and_align_labels,\n",
    "        batched=True,\n",
    "        remove_columns=[\"langs\", \"ner_tags\", \"tokens\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ca285f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'ner_tags', 'langs'],\n",
       "    num_rows: 12580\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_ch[\"de\"][\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3b9df98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6290/6290 [00:00<00:00, 32730.36 examples/s]\n"
     ]
    }
   ],
   "source": [
    "panx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6376ab08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': List(Value('int32')),\n",
       " 'attention_mask': List(Value('int8')),\n",
       " 'labels': List(Value('int64'))}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_de_encoded[\"train\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e32095",
   "metadata": {},
   "source": [
    "## Метрика качества\n",
    "\n",
    "Чтобы оценить модель для NER задачи используют обычные метрики для классификации (precision, recall, ...), но с некоторыми отличиями:\n",
    "- нужно учитывать сущности, состоящие из несколько слов. Если хотя бы в одной части сущности модель ошиблась, то прогноз можно считать неверным;\n",
    "- в подсчете метрик нельзя учитывать верно предсказанные токены, не являющиеся сущностями. Так как таких токенов больше всего, а нам важнее предсказать сущность, то эти предсказания вносят дисбаланс и метрика будет малоинформативна для нас.\n",
    "С такой механикой работает библиотека `seqeval`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef88023e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       0.00      0.00      0.00         1\n",
      "         PER       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.50      0.50         2\n",
      "weighted avg       0.50      0.50      0.50         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from seqeval.metrics import classification_report\n",
    "\n",
    "y_true = [\n",
    "    [\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "    [\"B-PER\", \"I-PER\", \"O\"],\n",
    "]\n",
    "\n",
    "y_pred = [\n",
    "    [\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "    [\"B-PER\", \"I-PER\", \"O\"],\n",
    "]\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d1eeca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_predictions(predictions, label_ids):\n",
    "    # predictions: (batch_size, seq_len, num_labels)\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "    batch_size, seq_len = preds.shape\n",
    "    labels_list, preds_list = [], []\n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "        example_labels, example_preds = [], []\n",
    "        for seq_idx in range(seq_len):\n",
    "            # ignore index = -100\n",
    "            if label_ids[batch_idx, seq_idx] != -100:\n",
    "                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
    "                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
    "\n",
    "        labels_list.append(example_labels)\n",
    "        preds_list.append(example_preds)\n",
    "\n",
    "    return preds_list, labels_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd156ea6",
   "metadata": {},
   "source": [
    "## Обучение модели\n",
    "\n",
    "[02.Multilingual-NER.Train.ipynb](02.Multilingual-NER.Train.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
