{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6a2353e",
   "metadata": {},
   "source": [
    "# Распознавание именованных сущностей\n",
    "*Обучение модели*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9682c9e8",
   "metadata": {},
   "source": [
    "## Определение классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e87ebea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misha/.pyenv/versions/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import (\n",
    "    load_dataset,\n",
    "    concatenate_datasets,\n",
    "    DatasetDict,\n",
    "    Dataset,\n",
    "    ClassLabel,\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    pipeline,\n",
    "    Pipeline,\n",
    "    AutoTokenizer,\n",
    "    XLMRobertaConfig,\n",
    "    RobertaModel,\n",
    "    RobertaPreTrainedModel,\n",
    "    DataCollatorForTokenClassification,\n",
    "    get_scheduler,\n",
    ")\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.pipelines.token_classification import AggregationStrategy\n",
    "from seqeval.metrics import f1_score\n",
    "from torchmetrics import Metric\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Literal\n",
    "from contextlib import contextmanager\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def disable_tokenizer_parallelism():\n",
    "    original_value = os.environ.get(\"TOKENIZERS_PARALLELISM\")\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        if original_value is not None:\n",
    "            os.environ[\"TOKENIZERS_PARALLELISM\"] = original_value\n",
    "        else:\n",
    "            os.environ.pop(\"TOKENIZERS_PARALLELISM\", None)\n",
    "\n",
    "\n",
    "class PANXDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = \"xlm-roberta-base\",\n",
    "        langs: list = [\"de\", \"fr\", \"it\", \"en\"],\n",
    "        train_langs: list = [\"de\"],\n",
    "        fracs: list = [0.629, 0.229, 0.084, 0.059],\n",
    "        batch_size: int = 24,\n",
    "        num_workers: int = 4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer: AutoTokenizer = None\n",
    "        self.data_collator: DataCollatorForTokenClassification = None\n",
    "\n",
    "        self.langs = langs\n",
    "        self.train_langs = train_langs.copy()\n",
    "        self.fracs = fracs\n",
    "\n",
    "        self.panx_ch = defaultdict(DatasetDict)\n",
    "        self.panx_tokenized = defaultdict(DatasetDict)\n",
    "        self.dataset: DatasetDict = None\n",
    "        self.tags: ClassLabel = None  # Метки (B-ORG, I-ORG, ...)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self._is_setuped = False\n",
    "\n",
    "    def prepare_data(self):\n",
    "        for lang in self.langs:\n",
    "            load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
    "        AutoTokenizer.from_pretrained(self.model_name)\n",
    "\n",
    "    def setup(self, stage: str | None = None):\n",
    "        if self._is_setuped:\n",
    "            return\n",
    "        # Загрузка токенизатора\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.data_collator = DataCollatorForTokenClassification(self.tokenizer)\n",
    "\n",
    "        # Загрузка датасетов согласно их частотам\n",
    "        for lang, frac in zip(self.langs, self.fracs):\n",
    "            ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
    "            for split in ds:\n",
    "                self.panx_ch[lang][split] = (\n",
    "                    ds[split]\n",
    "                    .shuffle(42)\n",
    "                    .select(range(int(frac * ds[split].num_rows)))\n",
    "                )\n",
    "\n",
    "        # tags\n",
    "        self.tags = (\n",
    "            self.panx_ch[self.langs[0]][\"train\"].features[\"ner_tags\"].feature\n",
    "        )\n",
    "\n",
    "        # tokenizig\n",
    "        for lang in self.langs:\n",
    "            self.panx_tokenized[lang] = self.tokenize_panx_dataset(\n",
    "                self.panx_ch[lang]\n",
    "            )\n",
    "        self._is_setuped = True\n",
    "\n",
    "    def set_train_langs(self, train_langs: list[str]):\n",
    "        self.train_langs = train_langs.copy()\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = self.concat_datasets(\n",
    "            [self.panx_tokenized[lang] for lang in self.train_langs], \"train\"\n",
    "        )\n",
    "        return DataLoader(\n",
    "            dataset[\"train\"],\n",
    "            self.batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=self.data_collator,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataloaders = []\n",
    "\n",
    "        for lang in self.langs:\n",
    "            dataset = self.panx_tokenized[lang][\"validation\"]\n",
    "            dataloader = DataLoader(\n",
    "                dataset,\n",
    "                self.batch_size,\n",
    "                shuffle=False,\n",
    "                collate_fn=self.data_collator,\n",
    "                num_workers=self.num_workers,\n",
    "            )\n",
    "            dataloaders.append(dataloader)\n",
    "\n",
    "        return dataloaders\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        dataloaders = []\n",
    "\n",
    "        for lang in self.langs:\n",
    "            dataset = self.panx_tokenized[lang][\"test\"]\n",
    "            dataloader = DataLoader(\n",
    "                dataset,\n",
    "                self.batch_size,\n",
    "                shuffle=False,\n",
    "                collate_fn=self.data_collator,\n",
    "                num_workers=self.num_workers,\n",
    "            )\n",
    "            dataloaders.append(dataloader)\n",
    "\n",
    "        return dataloaders\n",
    "\n",
    "    def tokenize_and_align_labels(self, examples):\n",
    "        tokenized_inputs = self.tokenizer(\n",
    "            examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "        )\n",
    "\n",
    "        labels = []\n",
    "        for idx, label in enumerate(examples[\"ner_tags\"]):\n",
    "            word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "            prev_word_idx = None\n",
    "            label_ids = []\n",
    "            for word_idx in word_ids:\n",
    "                if word_idx is None or word_idx == prev_word_idx:\n",
    "                    label_ids.append(-100)\n",
    "                else:\n",
    "                    label_ids.append(label[word_idx])\n",
    "                prev_word_idx = word_idx\n",
    "            labels.append(label_ids)\n",
    "        tokenized_inputs[\"labels\"] = labels\n",
    "        return tokenized_inputs\n",
    "\n",
    "    def tokenize_panx_dataset(self, corpus: DatasetDict):\n",
    "        return corpus.map(\n",
    "            self.tokenize_and_align_labels,\n",
    "            batched=True,\n",
    "            remove_columns=[\"langs\", \"ner_tags\", \"tokens\"],\n",
    "        )\n",
    "\n",
    "    # PANXDataModule.concatenate_datasets() takes 2 positional arguments but 3 were given\n",
    "    def concat_datasets(\n",
    "        self,\n",
    "        corpora: list[DatasetDict],\n",
    "        split: Literal[\"train\", \"validation\", \"test\"],\n",
    "    ) -> DatasetDict:\n",
    "        multi_corpus = DatasetDict()\n",
    "        multi_corpus[split] = concatenate_datasets(\n",
    "            [corpus[split] for corpus in corpora]\n",
    "        ).shuffle(seed=42)\n",
    "        return multi_corpus\n",
    "\n",
    "\n",
    "class SeqevalF1Metric(Metric):\n",
    "    def __init__(\n",
    "        self,\n",
    "        id2label: dict[int, str],\n",
    "        average: Literal[None, \"micro\", \"macro\", \"weighted\"] = \"micro\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.id2label = id2label\n",
    "        self.average = average\n",
    "        self.add_state(\n",
    "            \"total_f1\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\"\n",
    "        )\n",
    "        self.add_state(\n",
    "            \"total_batches\", default=torch.tensor(0), dist_reduce_fx=\"sum\"\n",
    "        )\n",
    "\n",
    "    def update(self, predictions: torch.Tensor, label_ids: torch.Tensor):\n",
    "        preds_list, labels_list = self._align_predictions(\n",
    "            predictions, label_ids\n",
    "        )\n",
    "        self.total_f1 += f1_score(\n",
    "            labels_list, preds_list, average=self.average\n",
    "        )\n",
    "        self.total_batches += 1\n",
    "\n",
    "    def compute(self):\n",
    "        if self.total_batches == 0:\n",
    "            return 0\n",
    "        return self.total_f1 / self.total_batches\n",
    "\n",
    "    def _align_predictions(\n",
    "        self, predictions: torch.Tensor, label_ids: torch.Tensor\n",
    "    ) -> tuple[list[list], list[list]]:\n",
    "        # predictions, labels_ids: (batch_size, seq_len)\n",
    "        predictions_cpu = predictions.cpu().numpy()\n",
    "        label_ids_cpu = label_ids.cpu().numpy()\n",
    "\n",
    "        batch_size, seq_len = predictions_cpu.shape\n",
    "        labels_list, preds_list = [], []\n",
    "\n",
    "        for batch_idx in range(batch_size):\n",
    "            example_labels, example_preds = [], []\n",
    "            for seq_idx in range(seq_len):\n",
    "                if label_ids[batch_idx, seq_idx] != -100:\n",
    "                    example_labels.append(\n",
    "                        self.id2label[label_ids_cpu[batch_idx, seq_idx]]\n",
    "                    )\n",
    "                    example_preds.append(\n",
    "                        self.id2label[predictions_cpu[batch_idx][seq_idx]]\n",
    "                    )\n",
    "            labels_list.append(example_labels)\n",
    "            preds_list.append(example_preds)\n",
    "\n",
    "        return preds_list, labels_list\n",
    "\n",
    "\n",
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        labels=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            **kwargs,\n",
    "        )\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "\n",
    "\n",
    "class plNERClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        config: XLMRobertaConfig,\n",
    "        langs: list,\n",
    "        lr: float = 1e-4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.langs = langs\n",
    "        self.config = config\n",
    "        self.lr = lr\n",
    "        self.model = XLMRobertaForTokenClassification.from_pretrained(\n",
    "            model_name, config=config\n",
    "        )\n",
    "\n",
    "        self.train_f1 = SeqevalF1Metric(config.id2label, average=\"micro\")\n",
    "\n",
    "        for lang in self.langs:\n",
    "            setattr(\n",
    "                self,\n",
    "                f\"val_f1_{lang}\",\n",
    "                SeqevalF1Metric(config.id2label, average=\"micro\"),\n",
    "            )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.model(**batch)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        output = self(batch)\n",
    "        logits, loss = output.logits, output.loss\n",
    "\n",
    "        self.train_f1.update(torch.argmax(logits, dim=-1), batch[\"labels\"])\n",
    "\n",
    "        self.log(\n",
    "            \"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True\n",
    "        )\n",
    "        self.log(\n",
    "            \"train_f1\",\n",
    "            self.train_f1,\n",
    "            prog_bar=True,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        lang = self.langs[dataloader_idx]\n",
    "        metric_name = f\"val_f1_{lang}\"\n",
    "\n",
    "        output = self(batch)\n",
    "        logits, loss = output.logits, output.loss\n",
    "\n",
    "        metric = getattr(self, metric_name)\n",
    "        metric.update(torch.argmax(logits, dim=-1), batch[\"labels\"])\n",
    "\n",
    "        self.log(\n",
    "            f\"val_loss_{lang}\",\n",
    "            loss,\n",
    "            prog_bar=False,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            add_dataloader_idx=False,\n",
    "        )\n",
    "\n",
    "        self.log(\n",
    "            metric_name,\n",
    "            metric,\n",
    "            prog_bar=True,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            metric_attribute=metric_name,\n",
    "            add_dataloader_idx=False,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "        num_training_steps = self.trainer.estimated_stepping_batches\n",
    "        num_warmup_steps = int(0.1 * num_training_steps)\n",
    "        scheduler = get_scheduler(\n",
    "            \"linear\",\n",
    "            optimizer,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_training_steps,\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "                \"frequency\": 1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "\n",
    "class NERPredictor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: XLMRobertaForTokenClassification,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        device: torch.device = \"cuda\",\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.model.eval()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "\n",
    "    def pipeline(self, device: torch.device = \"cuda\") -> Pipeline:\n",
    "        return pipeline(\n",
    "            \"token-classification\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            device=torch.device(\n",
    "                device if torch.cuda.is_available() else \"cpu\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    @torch.inference_mode\n",
    "    def tag_text(self, text: str) -> pd.DataFrame:\n",
    "        tokenized = self.tokenizer(text, return_tensors=\"pt\")\n",
    "        tokens = tokenized.tokens()\n",
    "        input_ids = tokenized.input_ids.to(self.device)\n",
    "        logits = self.model(input_ids).logits\n",
    "        predictions = torch.argmax(logits, dim=2)\n",
    "        preds = [\n",
    "            self.model.config.id2label[p] for p in predictions[0].cpu().numpy()\n",
    "        ]\n",
    "        return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def compute_loss_foreach_token(self, dataloader: DataLoader) -> Dataset:\n",
    "        device = self.device\n",
    "        model = self.model\n",
    "        tokenizer = self.tokenizer\n",
    "        id2label = model.config.id2label.copy()\n",
    "        id2label[-100] = \"IGN\"\n",
    "        num_labels = model.config.num_labels\n",
    "\n",
    "        def data_generator():\n",
    "            for batch in dataloader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "\n",
    "                losses = F.cross_entropy(\n",
    "                    logits.view(-1, num_labels),\n",
    "                    labels.view(-1),\n",
    "                    reduction=\"none\",\n",
    "                ).view(labels.shape)\n",
    "\n",
    "                preds = torch.argmax(logits, dim=-1)\n",
    "\n",
    "                input_ids = input_ids.cpu().numpy()\n",
    "                labels = labels.cpu().numpy()\n",
    "                preds = preds.cpu().numpy()\n",
    "                losses = losses.cpu().numpy()\n",
    "\n",
    "                for i in range(input_ids.shape[0]):\n",
    "                    tokens = tokenizer.convert_ids_to_tokens(\n",
    "                        input_ids[i].tolist()\n",
    "                    )\n",
    "                    true_labels = [\n",
    "                        id2label.get(int(l), \"UNK\") for l in labels[i]\n",
    "                    ]\n",
    "                    pred_labels = [\n",
    "                        id2label.get(int(p), \"UNK\") for p in preds[i]\n",
    "                    ]\n",
    "                    token_losses = losses[i].astype(float).tolist()\n",
    "\n",
    "                    yield {\n",
    "                        \"tokens\": tokens,\n",
    "                        \"true_labels\": true_labels,\n",
    "                        \"pred_labels\": pred_labels,\n",
    "                        \"token_losses\": token_losses,\n",
    "                    }\n",
    "\n",
    "        # динамическое создание Dataset без предварительного списка\n",
    "        dataset = Dataset.from_generator(data_generator)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "def get_metrics(path: Path):\n",
    "    df = pd.read_csv(path)\n",
    "    df = (\n",
    "        df[df[\"epoch\"] == df[\"epoch\"].max()]\n",
    "        .drop(\"step\", axis=1)\n",
    "        .groupby(\"epoch\")\n",
    "        .last()\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d91ce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"xlm-roberta-base\"\n",
    "LANGS = [\"de\", \"fr\", \"it\", \"en\"]\n",
    "TRAIN_LANGS = [\"de\"]\n",
    "FRACS = [0.629, 0.229, 0.084, 0.059]\n",
    "BATCH_SIZE = 24\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "EXPERIMENTS_PATH = Path(\"NER\")\n",
    "\n",
    "\n",
    "def get_trainer(train_langs: list[str]) -> pl.Trainer:\n",
    "    experiment_path = Path(EXPERIMENTS_PATH, \"-\".join(train_langs))\n",
    "    CHECKPOINT_PATH = experiment_path / \"checkpoints\"\n",
    "    CHECKPOINT_PATH.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    callbacks = [\n",
    "        TQDMProgressBar(leave=True),\n",
    "        ModelCheckpoint(\n",
    "            dirpath=CHECKPOINT_PATH,\n",
    "            filename=\"last\",\n",
    "            save_last=True,\n",
    "            save_top_k=0,\n",
    "        ),\n",
    "    ]\n",
    "    logger = CSVLogger(save_dir=experiment_path, name=\"logs\")\n",
    "    last_ckpt_path = CHECKPOINT_PATH / \"last.ckpt\"\n",
    "    ckpt_path = last_ckpt_path if last_ckpt_path.exists() else None\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=NUM_EPOCHS,\n",
    "        devices=1,\n",
    "        callbacks=callbacks,\n",
    "        logger=logger if not ckpt_path else False,\n",
    "    )\n",
    "    return trainer, ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95cb3696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4580/4580 [00:00<00:00, 39940.85 examples/s]\n",
      "Map: 100%|██████████| 1680/1680 [00:00<00:00, 36196.80 examples/s]\n",
      "Map: 100%|██████████| 840/840 [00:00<00:00, 34142.33 examples/s]\n",
      "Map: 100%|██████████| 840/840 [00:00<00:00, 33491.60 examples/s]\n",
      "Map: 100%|██████████| 1180/1180 [00:00<00:00, 33727.07 examples/s]\n",
      "Map: 100%|██████████| 590/590 [00:00<00:00, 30185.52 examples/s]\n",
      "Map: 100%|██████████| 590/590 [00:00<00:00, 30158.30 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dm = PANXDataModule(\n",
    "    MODEL_NAME, LANGS, TRAIN_LANGS, FRACS, BATCH_SIZE, NUM_WORKERS\n",
    ")\n",
    "dm.prepare_data()\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a3aa4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {idx: tag for idx, tag in enumerate(dm.tags.names)}\n",
    "label2id = {tag: idx for idx, tag in id2label.items()}\n",
    "\n",
    "xlmr_config = XLMRobertaConfig.from_pretrained(\n",
    "    MODEL_NAME, num_labels=len(id2label), id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf9de9",
   "metadata": {},
   "source": [
    "## Обучение только на немецком датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26d3717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "pl_model = plNERClassifier(\n",
    "    model_name=MODEL_NAME,\n",
    "    config=xlmr_config,\n",
    "    langs=LANGS,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "trainer, ckpt_path = get_trainer(TRAIN_LANGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7dd547b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 5070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Restoring states from the checkpoint path at NER/de/checkpoints/last.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name      | Type                             | Params | Mode \n",
      "-----------------------------------------------------------------------\n",
      "0 | model     | XLMRobertaForTokenClassification | 277 M  | eval \n",
      "1 | train_f1  | SeqevalF1Metric                  | 0      | train\n",
      "2 | val_f1_de | SeqevalF1Metric                  | 0      | train\n",
      "3 | val_f1_fr | SeqevalF1Metric                  | 0      | train\n",
      "4 | val_f1_it | SeqevalF1Metric                  | 0      | train\n",
      "5 | val_f1_en | SeqevalF1Metric                  | 0      | train\n",
      "-----------------------------------------------------------------------\n",
      "277 M     Trainable params\n",
      "0         Non-trainable params\n",
      "277 M     Total params\n",
      "1,109.834 Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "228       Modules in eval mode\n",
      "Restored all states from the checkpoint at NER/de/checkpoints/last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Модель загружена из памяти NER/de/checkpoints/last.ckpt\n"
     ]
    }
   ],
   "source": [
    "with disable_tokenizer_parallelism():\n",
    "    trainer.fit(pl_model, datamodule=dm, ckpt_path=ckpt_path)\n",
    "    if ckpt_path:\n",
    "        print(f\"\\nМодель загружена из памяти {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb226941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_f1_de</th>\n",
       "      <th>val_f1_en</th>\n",
       "      <th>val_f1_fr</th>\n",
       "      <th>val_f1_it</th>\n",
       "      <th>val_loss_de</th>\n",
       "      <th>val_loss_en</th>\n",
       "      <th>val_loss_fr</th>\n",
       "      <th>val_loss_it</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.973679</td>\n",
       "      <td>0.019325</td>\n",
       "      <td>0.86197</td>\n",
       "      <td>0.585224</td>\n",
       "      <td>0.702495</td>\n",
       "      <td>0.628935</td>\n",
       "      <td>0.143299</td>\n",
       "      <td>0.974609</td>\n",
       "      <td>0.869035</td>\n",
       "      <td>1.038661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_f1  train_loss  val_f1_de  val_f1_en  val_f1_fr  val_f1_it  \\\n",
       "epoch                                                                     \n",
       "4      0.973679    0.019325    0.86197   0.585224   0.702495   0.628935   \n",
       "\n",
       "       val_loss_de  val_loss_en  val_loss_fr  val_loss_it  \n",
       "epoch                                                      \n",
       "4         0.143299     0.974609     0.869035     1.038661  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_metrics(EXPERIMENTS_PATH / \"de/logs/version_0/metrics.csv\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be5cb633",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = NERPredictor(\n",
    "    pl_model.model,\n",
    "    tokenizer=dm.tokenizer,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a146526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_292d1 td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_292d1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_292d1_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_292d1_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_292d1_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_292d1_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_292d1_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_292d1_level0_col5\" class=\"col_heading level0 col5\" >5</th>\n",
       "      <th id=\"T_292d1_level0_col6\" class=\"col_heading level0 col6\" >6</th>\n",
       "      <th id=\"T_292d1_level0_col7\" class=\"col_heading level0 col7\" >7</th>\n",
       "      <th id=\"T_292d1_level0_col8\" class=\"col_heading level0 col8\" >8</th>\n",
       "      <th id=\"T_292d1_level0_col9\" class=\"col_heading level0 col9\" >9</th>\n",
       "      <th id=\"T_292d1_level0_col10\" class=\"col_heading level0 col10\" >10</th>\n",
       "      <th id=\"T_292d1_level0_col11\" class=\"col_heading level0 col11\" >11</th>\n",
       "      <th id=\"T_292d1_level0_col12\" class=\"col_heading level0 col12\" >12</th>\n",
       "      <th id=\"T_292d1_level0_col13\" class=\"col_heading level0 col13\" >13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_292d1_level0_row0\" class=\"row_heading level0 row0\" >Tokens</th>\n",
       "      <td id=\"T_292d1_row0_col0\" class=\"data row0 col0\" ><s></td>\n",
       "      <td id=\"T_292d1_row0_col1\" class=\"data row0 col1\" >▁Jeff</td>\n",
       "      <td id=\"T_292d1_row0_col2\" class=\"data row0 col2\" >▁De</td>\n",
       "      <td id=\"T_292d1_row0_col3\" class=\"data row0 col3\" >an</td>\n",
       "      <td id=\"T_292d1_row0_col4\" class=\"data row0 col4\" >▁ist</td>\n",
       "      <td id=\"T_292d1_row0_col5\" class=\"data row0 col5\" >▁ein</td>\n",
       "      <td id=\"T_292d1_row0_col6\" class=\"data row0 col6\" >▁Informati</td>\n",
       "      <td id=\"T_292d1_row0_col7\" class=\"data row0 col7\" >ker</td>\n",
       "      <td id=\"T_292d1_row0_col8\" class=\"data row0 col8\" >▁bei</td>\n",
       "      <td id=\"T_292d1_row0_col9\" class=\"data row0 col9\" >▁Google</td>\n",
       "      <td id=\"T_292d1_row0_col10\" class=\"data row0 col10\" >▁in</td>\n",
       "      <td id=\"T_292d1_row0_col11\" class=\"data row0 col11\" >▁Kaliforni</td>\n",
       "      <td id=\"T_292d1_row0_col12\" class=\"data row0 col12\" >en</td>\n",
       "      <td id=\"T_292d1_row0_col13\" class=\"data row0 col13\" ></s></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_292d1_level0_row1\" class=\"row_heading level0 row1\" >Tags</th>\n",
       "      <td id=\"T_292d1_row1_col0\" class=\"data row1 col0\" >O</td>\n",
       "      <td id=\"T_292d1_row1_col1\" class=\"data row1 col1\" >B-PER</td>\n",
       "      <td id=\"T_292d1_row1_col2\" class=\"data row1 col2\" >I-PER</td>\n",
       "      <td id=\"T_292d1_row1_col3\" class=\"data row1 col3\" >I-PER</td>\n",
       "      <td id=\"T_292d1_row1_col4\" class=\"data row1 col4\" >O</td>\n",
       "      <td id=\"T_292d1_row1_col5\" class=\"data row1 col5\" >O</td>\n",
       "      <td id=\"T_292d1_row1_col6\" class=\"data row1 col6\" >O</td>\n",
       "      <td id=\"T_292d1_row1_col7\" class=\"data row1 col7\" >O</td>\n",
       "      <td id=\"T_292d1_row1_col8\" class=\"data row1 col8\" >O</td>\n",
       "      <td id=\"T_292d1_row1_col9\" class=\"data row1 col9\" >B-ORG</td>\n",
       "      <td id=\"T_292d1_row1_col10\" class=\"data row1 col10\" >O</td>\n",
       "      <td id=\"T_292d1_row1_col11\" class=\"data row1 col11\" >B-LOC</td>\n",
       "      <td id=\"T_292d1_row1_col12\" class=\"data row1 col12\" >I-LOC</td>\n",
       "      <td id=\"T_292d1_row1_col13\" class=\"data row1 col13\" >O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7c038b9e2660>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Jeff Dean ist ein Informatiker bei Google in Kalifornien\"\n",
    "\n",
    "styles = [{\"selector\": \"td\", \"props\": [(\"white-space\", \"nowrap\")]}]\n",
    "\n",
    "predictor.tag_text(text).style.set_table_styles(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e011b5b",
   "metadata": {},
   "source": [
    "## Анализ ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f75e2d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'true_labels', 'pred_labels', 'token_losses'],\n",
       "    num_rows: 6290\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with disable_tokenizer_parallelism():\n",
    "    error_analysis_set = predictor.compute_loss_foreach_token(\n",
    "        dm.val_dataloader()[0]\n",
    "    )\n",
    "error_analysis_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f53218c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = error_analysis_set.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f644cfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>pred_labels</th>\n",
       "      <th>token_losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[&lt;s&gt;, ▁Hon, ., DU, ni, v, ▁;, ▁University, ▁of, ▁Kwa, Z, ulu, -, Na, tal, &lt;/s&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;, &lt;pad&gt;]</td>\n",
       "      <td>[IGN, O, IGN, IGN, IGN, IGN, O, B-ORG, I-ORG, I-ORG, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN]</td>\n",
       "      <td>[I-ORG, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[0.0, 0.07230185717344284, 0.0, 0.0, 0.0, 0.0, 0.003627982921898365, 0.0018816161900758743, 0.0018314032349735498, 0.002080658683553338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                  tokens  \\\n",
       "0  [<s>, ▁Hon, ., DU, ni, v, ▁;, ▁University, ▁of, ▁Kwa, Z, ulu, -, Na, tal, </s>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>, <pad>]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                            true_labels  \\\n",
       "0  [IGN, O, IGN, IGN, IGN, IGN, O, B-ORG, I-ORG, I-ORG, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN, IGN]   \n",
       "\n",
       "                                                                                                                                                                                                              pred_labels  \\\n",
       "0  [I-ORG, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, I-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                               token_losses  \n",
       "0  [0.0, 0.07230185717344284, 0.0, 0.0, 0.0, 0.0, 0.003627982921898365, 0.0018816161900758743, 0.0018314032349735498, 0.002080658683553338, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context(\"display.max_colwidth\", None):\n",
    "    display(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afdb275c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>pred_labels</th>\n",
       "      <th>token_losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁Hon</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁;</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁University</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁of</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>▁Kwa</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁'</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▁''</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tokens true_labels pred_labels  token_losses\n",
       "0         ▁Hon           O           O          0.07\n",
       "0           ▁;           O           O          0.00\n",
       "0  ▁University       B-ORG       B-ORG          0.00\n",
       "0          ▁of       I-ORG       I-ORG          0.00\n",
       "0         ▁Kwa       I-ORG       I-ORG          0.00\n",
       "1           ▁'           O           O          0.00\n",
       "1          ▁''           O           O          0.00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = df.apply(pd.Series.explode)\n",
    "df_tokens = df_tokens.query(\"true_labels != 'IGN'\")\n",
    "df_tokens[\"token_losses\"] = df_tokens[\"token_losses\"].astype(float).round(2)\n",
    "df_tokens.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c2479",
   "metadata": {},
   "source": [
    "Посмотрим, какой токен вносит больше всего ошибок в валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4b73abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>tokens</th>\n",
       "      <th>▁</th>\n",
       "      <th>▁von</th>\n",
       "      <th>▁(</th>\n",
       "      <th>▁der</th>\n",
       "      <th>▁)</th>\n",
       "      <th>▁/</th>\n",
       "      <th>▁in</th>\n",
       "      <th>▁und</th>\n",
       "      <th>▁des</th>\n",
       "      <th>▁B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5967.00</td>\n",
       "      <td>796.00</td>\n",
       "      <td>246.00</td>\n",
       "      <td>1355.00</td>\n",
       "      <td>246.00</td>\n",
       "      <td>160.00</td>\n",
       "      <td>990.00</td>\n",
       "      <td>1140.00</td>\n",
       "      <td>342.00</td>\n",
       "      <td>52.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>141.64</td>\n",
       "      <td>118.20</td>\n",
       "      <td>106.93</td>\n",
       "      <td>98.26</td>\n",
       "      <td>95.57</td>\n",
       "      <td>94.47</td>\n",
       "      <td>91.24</td>\n",
       "      <td>69.74</td>\n",
       "      <td>58.45</td>\n",
       "      <td>53.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "tokens        ▁    ▁von      ▁(     ▁der      ▁)      ▁/     ▁in     ▁und  \\\n",
       "count   5967.00  796.00  246.00  1355.00  246.00  160.00  990.00  1140.00   \n",
       "mean       0.02    0.15    0.43     0.07    0.39    0.59    0.09     0.06   \n",
       "sum      141.64  118.20  106.93    98.26   95.57   94.47   91.24    69.74   \n",
       "\n",
       "tokens    ▁des     ▁B  \n",
       "count   342.00  52.00  \n",
       "mean      0.17   1.03  \n",
       "sum      58.45  53.52  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens.groupby(\"tokens\")[\"token_losses\"].agg(\n",
    "    [\"count\", \"mean\", \"sum\"]\n",
    ").sort_values(by=\"sum\", ascending=False).round(2).head(10).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd858a6",
   "metadata": {},
   "source": [
    "- Токен пробела имеет наибольшую общую потерю, что не удивительно, так как он встречается в данных чаще всего. Однако его средняя потеря ниже, чем у остальных в списке, что говорит о том, что модель не испытывает трудностей с его классификацией.\n",
    "- Такие токены, как \"in\", \"von\", \"der\" и \"und\" имеют относительно большую частоты. Они не редко встречаются с именованными сущностями, что объясняет, почему модель может их путать.\n",
    "- Скобки, косые черты и заглавные буквы в начале слов встречаются реже, но имеют относительно высокий средний уровень потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda2baa",
   "metadata": {},
   "source": [
    "Также можно сравнить, насколько хорошо модель предсказывает каждый тег."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "723c4ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>true_labels</th>\n",
       "      <th>I-LOC</th>\n",
       "      <th>B-ORG</th>\n",
       "      <th>I-ORG</th>\n",
       "      <th>B-LOC</th>\n",
       "      <th>B-PER</th>\n",
       "      <th>I-PER</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1447.00</td>\n",
       "      <td>2639.00</td>\n",
       "      <td>3774.00</td>\n",
       "      <td>3172.00</td>\n",
       "      <td>2870.00</td>\n",
       "      <td>4140.00</td>\n",
       "      <td>43122.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>893.94</td>\n",
       "      <td>1582.52</td>\n",
       "      <td>1822.44</td>\n",
       "      <td>1248.34</td>\n",
       "      <td>859.31</td>\n",
       "      <td>906.49</td>\n",
       "      <td>1341.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "true_labels    I-LOC    B-ORG    I-ORG    B-LOC    B-PER    I-PER         O\n",
       "count        1447.00  2639.00  3774.00  3172.00  2870.00  4140.00  43122.00\n",
       "mean            0.62     0.60     0.48     0.39     0.30     0.22      0.03\n",
       "sum           893.94  1582.52  1822.44  1248.34   859.31   906.49   1341.28"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens.groupby(\"true_labels\")[\"token_losses\"].agg(\n",
    "    [\"count\", \"mean\", \"sum\"]\n",
    ").sort_values(by=\"mean\", ascending=False).round(2).head(10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5d3d68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    df_tokens[\"pred_labels\"], df_tokens[\"true_labels\"], dm.tags.names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1727d0fe",
   "metadata": {},
   "source": [
    "В основном, модель имеет хорошее качества, что видно по темной диагонали. Но она часта путает `B-ORG` и `I-ORG`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161c0544",
   "metadata": {},
   "source": [
    "Теперь посмотрим на предложения с высокой средней ошибкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bcdc533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Schwa</td>\n",
       "      <td>n</td>\n",
       "      <td>dorf</td>\n",
       "      <td>▁–</td>\n",
       "      <td>▁Cham</td>\n",
       "      <td>▁–</td>\n",
       "      <td>▁Fur</td>\n",
       "      <td>th</td>\n",
       "      <td>▁im</td>\n",
       "      <td>▁Wald</td>\n",
       "      <td>...</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁als</td>\n",
       "      <td>▁Teil</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Fern</td>\n",
       "      <td>verbindung</td>\n",
       "      <td>▁München</td>\n",
       "      <td>▁-</td>\n",
       "      <td>▁Prag</td>\n",
       "      <td>▁)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>...</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_labels</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_losses</th>\n",
       "      <td>4.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.63</td>\n",
       "      <td>8.71</td>\n",
       "      <td>7.53</td>\n",
       "      <td>8.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.04</td>\n",
       "      <td>5.58</td>\n",
       "      <td>...</td>\n",
       "      <td>3.90</td>\n",
       "      <td>5.30</td>\n",
       "      <td>7.77</td>\n",
       "      <td>7.37</td>\n",
       "      <td>5.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.53</td>\n",
       "      <td>2.61</td>\n",
       "      <td>1.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0      1      2      3      4      5      6      7      8   \\\n",
       "tokens        ▁Schwa      n   dorf     ▁–  ▁Cham     ▁–   ▁Fur     th    ▁im   \n",
       "true_labels    B-ORG    IGN    IGN  I-ORG  I-ORG  I-ORG  I-ORG    IGN  I-ORG   \n",
       "pred_labels    B-LOC  I-LOC  I-LOC      O  B-LOC      O  B-LOC  B-LOC  I-LOC   \n",
       "token_losses    4.23   0.00   0.00   7.63   8.71   7.53   8.13   0.00   5.04   \n",
       "\n",
       "                 9   ...     16     17     18     19     20          21  \\\n",
       "tokens        ▁Wald  ...     ▁(   ▁als  ▁Teil   ▁der  ▁Fern  verbindung   \n",
       "true_labels   I-ORG  ...  I-ORG  I-ORG  I-ORG  I-ORG  I-ORG         IGN   \n",
       "pred_labels   I-LOC  ...      O      O      O      O      O           O   \n",
       "token_losses   5.58  ...   3.90   5.30   7.77   7.37   5.16        0.00   \n",
       "\n",
       "                    22     23     24     25  \n",
       "tokens        ▁München     ▁-  ▁Prag     ▁)  \n",
       "true_labels      I-ORG  I-ORG  I-ORG  I-ORG  \n",
       "pred_labels      I-ORG      O  I-LOC  I-LOC  \n",
       "token_losses      0.93   1.53   2.61   1.45  \n",
       "\n",
       "[4 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁''</td>\n",
       "      <td>8</td>\n",
       "      <td>.</td>\n",
       "      <td>▁Juli</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁:</td>\n",
       "      <td>▁Protest</td>\n",
       "      <td>camp</td>\n",
       "      <td>▁auf</td>\n",
       "      <td>▁dem</td>\n",
       "      <td>▁Gelände</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Republika</td>\n",
       "      <td>n</td>\n",
       "      <td>ischen</td>\n",
       "      <td>▁Gar</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_losses</th>\n",
       "      <td>8.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.82</td>\n",
       "      <td>9.20</td>\n",
       "      <td>9.23</td>\n",
       "      <td>6.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.44</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.01</td>\n",
       "      <td>3.11</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0     1     2      3      4      5         6     7      8   \\\n",
       "tokens          ▁''     8     .  ▁Juli    ▁''     ▁:  ▁Protest  camp   ▁auf   \n",
       "true_labels   B-ORG   IGN   IGN  I-ORG  I-ORG  I-ORG     I-ORG   IGN  I-ORG   \n",
       "pred_labels       O     O     O      O      O      O         O     O      O   \n",
       "token_losses   8.68  0.00  0.00   4.82   9.20   9.23      6.23  0.00   7.44   \n",
       "\n",
       "                 9         10     11          12     13      14     15     16  \n",
       "tokens         ▁dem  ▁Gelände   ▁der  ▁Republika      n  ischen   ▁Gar     de  \n",
       "true_labels   I-ORG     I-ORG  I-ORG       I-ORG    IGN     IGN  I-ORG    IGN  \n",
       "pred_labels       O         O      O       B-ORG  I-ORG   I-ORG  I-ORG  I-ORG  \n",
       "token_losses   7.65      7.01   3.11        2.28   0.00    0.00   0.02   0.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Im</td>\n",
       "      <td>▁Jahr</td>\n",
       "      <td>▁2006</td>\n",
       "      <td>▁spielt</td>\n",
       "      <td>e</td>\n",
       "      <td>▁sie</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁einigen</td>\n",
       "      <td>▁Folgen</td>\n",
       "      <td>▁der</td>\n",
       "      <td>...</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁''</td>\n",
       "      <td>Bro</td>\n",
       "      <td>oke</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁über</td>\n",
       "      <td>nah</td>\n",
       "      <td>m</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_losses</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0      1      2        3     4     5     6         7   \\\n",
       "tokens         ▁Im  ▁Jahr  ▁2006  ▁spielt     e  ▁sie   ▁in  ▁einigen   \n",
       "true_labels      O      O      O        O   IGN     O     O         O   \n",
       "pred_labels      O      O      O        O     O     O     O         O   \n",
       "token_losses  0.00   0.00   0.00     0.00  0.00  0.00  0.00      0.00   \n",
       "\n",
       "                   8     9   ...    27    28     29    30    31     32    33  \\\n",
       "tokens        ▁Folgen  ▁der  ...  ▁der   ▁''    Bro   oke   ▁''  ▁über   nah   \n",
       "true_labels         O     O  ...     O     O    IGN   IGN     O      O   IGN   \n",
       "pred_labels         O     O  ...     O     O  B-PER     O     O      O     O   \n",
       "token_losses     0.00  0.00  ...  0.00  0.00   0.00  0.00  0.00   0.00  0.00   \n",
       "\n",
       "                34    35    36  \n",
       "tokens           m     ▁     .  \n",
       "true_labels    IGN     O   IGN  \n",
       "pred_labels      O     O     O  \n",
       "token_losses  0.00  0.00  0.00  \n",
       "\n",
       "[4 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_samples(df):\n",
    "    for _, row in df.iterrows():\n",
    "        labels, preds, tokens, losses = [], [], [], []\n",
    "        # Проходим по всем элементам, исключая первый и последний (если нужно)\n",
    "        for i in range(1, (row[\"tokens\"] != \"<pad>\").sum() - 1):\n",
    "            labels.append(row[\"true_labels\"][i])\n",
    "            preds.append(row[\"pred_labels\"][i])\n",
    "            tokens.append(row[\"tokens\"][i])\n",
    "            losses.append(f\"{row['token_losses'][i]:.2f}\")\n",
    "\n",
    "        df_tmp = pd.DataFrame(\n",
    "            {\n",
    "                \"tokens\": tokens,\n",
    "                \"true_labels\": labels,\n",
    "                \"pred_labels\": preds,\n",
    "                \"token_losses\": losses,\n",
    "            }\n",
    "        ).T\n",
    "        yield df_tmp\n",
    "\n",
    "\n",
    "df[\"total_loss\"] = df[\"token_losses\"].apply(sum)\n",
    "df_tmp = df.sort_values(by=\"total_loss\", ascending=False).head(3)\n",
    "\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e30554",
   "metadata": {},
   "source": [
    "Можно видеть, что в разметке данных тоже есть ошибки. Наприме, “8. Juli” помечена как организация. Датасеты PAN-X создавался автоматическими способами, поэтому ошибки не удивительны."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646ae94",
   "metadata": {},
   "source": [
    "Мы говорили, что у скобок и слэшов тоже большие ошибки. Давайте посмотрим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8e7f8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁German</td>\n",
       "      <td>▁Master</td>\n",
       "      <td>s</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁S</td>\n",
       "      <td>no</td>\n",
       "      <td>ok</td>\n",
       "      <td>er</td>\n",
       "      <td>▁)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_labels</th>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_losses</th>\n",
       "      <td>3.25</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.47</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0        1      2      3      4      5      6      7  \\\n",
       "tokens        ▁German  ▁Master      s     ▁(     ▁S     no     ok     er   \n",
       "true_labels     B-PER    I-PER    IGN  I-PER  I-PER    IGN    IGN    IGN   \n",
       "pred_labels     B-ORG    I-ORG  I-ORG  I-ORG  I-ORG  I-ORG  I-ORG  I-ORG   \n",
       "token_losses     3.25     3.82   0.00   3.47   3.30   0.00   0.00   0.00   \n",
       "\n",
       "                  8  \n",
       "tokens           ▁)  \n",
       "true_labels   I-PER  \n",
       "pred_labels   I-ORG  \n",
       "token_losses   3.54  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Drag</td>\n",
       "      <td>e</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁El</td>\n",
       "      <td>be</td>\n",
       "      <td>▁)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_labels</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_labels</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token_losses</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0      1      2      3      4      5\n",
       "tokens        ▁Drag      e     ▁(    ▁El     be     ▁)\n",
       "true_labels   B-LOC    IGN  I-LOC  I-LOC    IGN  I-LOC\n",
       "pred_labels   B-LOC  I-LOC  I-LOC  I-LOC  I-LOC  I-LOC\n",
       "token_losses   0.01   0.00   0.01   0.01   0.00   0.01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tmp = df.loc[df[\"tokens\"].apply(lambda x: \"\\u2581(\" in x)].head(2)\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a813183f",
   "metadata": {},
   "source": [
    "Как правило, мы не включаем скобки и их содержимое в именованные объекты, однако, по-видимому, алгоритм автоматического извлечения аннотаций работает именно так. В других примерах в скобках указывается географическая принадлежность. Хотя это и является местоположением, нам стоит вынести эту информацию в отдельное поле аннотации. Данный набор данных состоит из многоязычных статей Википедии, где пояснения в скобках — это обычное дело. Например, в первом примере «(Unternehmen)» уточняет, что «Hama» — это компания. Эти детали важно учитывать при внедрении модели, поскольку они могут повлиять на производительность всего конвейера, частью которого она является."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a629e73",
   "metadata": {},
   "source": [
    "## Обучение на всех языках"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c3a3b",
   "metadata": {},
   "source": [
    "До этого мы дообучали модель только на немецком языке и, благодаря cross lingual transfer learning, смогли предсказывать и на других языках.\n",
    "\n",
    "Вот такие результаты получили."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69bedfd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_f1_de</th>\n",
       "      <th>val_f1_en</th>\n",
       "      <th>val_f1_fr</th>\n",
       "      <th>val_f1_it</th>\n",
       "      <th>val_loss_de</th>\n",
       "      <th>val_loss_en</th>\n",
       "      <th>val_loss_fr</th>\n",
       "      <th>val_loss_it</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.973679</td>\n",
       "      <td>0.019325</td>\n",
       "      <td>0.86197</td>\n",
       "      <td>0.585224</td>\n",
       "      <td>0.702495</td>\n",
       "      <td>0.628935</td>\n",
       "      <td>0.143299</td>\n",
       "      <td>0.974609</td>\n",
       "      <td>0.869035</td>\n",
       "      <td>1.038661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_f1  train_loss  val_f1_de  val_f1_en  val_f1_fr  val_f1_it  \\\n",
       "epoch                                                                     \n",
       "4      0.973679    0.019325    0.86197   0.585224   0.702495   0.628935   \n",
       "\n",
       "       val_loss_de  val_loss_en  val_loss_fr  val_loss_it  \n",
       "epoch                                                      \n",
       "4         0.143299     0.974609     0.869035     1.038661  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ef87d5",
   "metadata": {},
   "source": [
    "Посмотрим, что будет, если дообучить модель на всех языках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9b13c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.set_train_langs(LANGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "006aa7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "pl_model = plNERClassifier(\n",
    "    model_name=MODEL_NAME,\n",
    "    config=xlmr_config,\n",
    "    langs=LANGS,\n",
    "    lr=2e-5,\n",
    ")\n",
    "\n",
    "trainer, ckpt_path = get_trainer(train_langs=LANGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5f6a3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at NER/de-fr-it-en/checkpoints/last.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loading `train_dataloader` to estimate number of stepping batches.\n",
      "\n",
      "  | Name      | Type                             | Params | Mode \n",
      "-----------------------------------------------------------------------\n",
      "0 | model     | XLMRobertaForTokenClassification | 277 M  | eval \n",
      "1 | train_f1  | SeqevalF1Metric                  | 0      | train\n",
      "2 | val_f1_de | SeqevalF1Metric                  | 0      | train\n",
      "3 | val_f1_fr | SeqevalF1Metric                  | 0      | train\n",
      "4 | val_f1_it | SeqevalF1Metric                  | 0      | train\n",
      "5 | val_f1_en | SeqevalF1Metric                  | 0      | train\n",
      "-----------------------------------------------------------------------\n",
      "277 M     Trainable params\n",
      "0         Non-trainable params\n",
      "277 M     Total params\n",
      "1,109.834 Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "228       Modules in eval mode\n",
      "Restored all states from the checkpoint at NER/de-fr-it-en/checkpoints/last.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Модель загружена из памяти NER/de-fr-it-en/checkpoints/last.ckpt\n"
     ]
    }
   ],
   "source": [
    "with disable_tokenizer_parallelism():\n",
    "    trainer.fit(pl_model, datamodule=dm, ckpt_path=ckpt_path)\n",
    "    if ckpt_path:\n",
    "        print(f\"\\nМодель загружена из памяти {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c5b585e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_f1_de</th>\n",
       "      <th>val_f1_en</th>\n",
       "      <th>val_f1_fr</th>\n",
       "      <th>val_f1_it</th>\n",
       "      <th>val_loss_de</th>\n",
       "      <th>val_loss_en</th>\n",
       "      <th>val_loss_fr</th>\n",
       "      <th>val_loss_it</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.975209</td>\n",
       "      <td>0.021228</td>\n",
       "      <td>0.861605</td>\n",
       "      <td>0.761855</td>\n",
       "      <td>0.858979</td>\n",
       "      <td>0.841434</td>\n",
       "      <td>0.150952</td>\n",
       "      <td>0.423125</td>\n",
       "      <td>0.273808</td>\n",
       "      <td>0.276041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       train_f1  train_loss  val_f1_de  val_f1_en  val_f1_fr  val_f1_it  \\\n",
       "epoch                                                                     \n",
       "4      0.975209    0.021228   0.861605   0.761855   0.858979   0.841434   \n",
       "\n",
       "       val_loss_de  val_loss_en  val_loss_fr  val_loss_it  \n",
       "epoch                                                      \n",
       "4         0.150952     0.423125     0.273808     0.276041  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_langs_results = get_metrics(\n",
    "    EXPERIMENTS_PATH / \"de-fr-it-en/logs/version_0/metrics.csv\"\n",
    ")\n",
    "all_langs_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d6fbbb",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "- Cross Lingual Transfer лучше работает для похожих языков. То есть мы обучили модель на немецком, и получили лучшие результаты на валидации французского и итальянского языков, чем на английском. Немецкий, французский и итальянский ближе друг к другу, чем английский.\n",
    "- Обучение на всех языках дает лучшее качество. Но если языки схожи, то можно использовать и cross lingual transfer. Например, в японском языке это может быть хорошим решением."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
